{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c33843a8",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-02-11T18:06:52.656723Z",
     "iopub.status.busy": "2024-02-11T18:06:52.656293Z",
     "iopub.status.idle": "2024-02-11T18:07:27.845373Z",
     "shell.execute_reply": "2024-02-11T18:07:27.844162Z"
    },
    "papermill": {
     "duration": 35.199757,
     "end_time": "2024-02-11T18:07:27.847999",
     "exception": false,
     "start_time": "2024-02-11T18:06:52.648242",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install /kaggle/input/save-smp/segmentation_models_pytorch/{segmentation_models_pytorch-0.3.3-py3-none-any.whl,pretrainedmodels-0.7.4-py3-none-any.whl,efficientnet_pytorch-0.7.1-py3-none-any.whl,timm-0.9.2-py3-none-any.whl,munch-4.0.0-py2.py3-none-any.whl}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8135ef9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-11T18:07:27.862752Z",
     "iopub.status.busy": "2024-02-11T18:07:27.862396Z",
     "iopub.status.idle": "2024-02-11T18:07:37.108916Z",
     "shell.execute_reply": "2024-02-11T18:07:37.107819Z"
    },
    "papermill": {
     "duration": 9.256672,
     "end_time": "2024-02-11T18:07:37.111415",
     "exception": false,
     "start_time": "2024-02-11T18:07:27.854743",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'segmentation_models_pytorch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msegmentation_models_pytorch\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msmp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'segmentation_models_pytorch'"
     ]
    }
   ],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from glob import glob\n",
    "import os\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tifffile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import albumentations as A\n",
    "import albumentations.pytorch as AT\n",
    "from torchvision import transforms\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7733a62f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-11T18:07:37.126202Z",
     "iopub.status.busy": "2024-02-11T18:07:37.125436Z",
     "iopub.status.idle": "2024-02-11T18:07:37.133146Z",
     "shell.execute_reply": "2024-02-11T18:07:37.132255Z"
    },
    "papermill": {
     "duration": 0.016966,
     "end_time": "2024-02-11T18:07:37.135093",
     "exception": false,
     "start_time": "2024-02-11T18:07:37.118127",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class UnetUpscale(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        encoder_name,\n",
    "        decoder_use_batchnorm,\n",
    "        in_channels,\n",
    "        classes,\n",
    "        encoder_weights,\n",
    "        upscale_factor,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.upscale_factor = upscale_factor\n",
    "\n",
    "        self.model = smp.Unet(\n",
    "            encoder_name=encoder_name,\n",
    "            decoder_use_batchnorm=decoder_use_batchnorm,\n",
    "            in_channels=in_channels,\n",
    "            classes=classes,\n",
    "            encoder_weights=encoder_weights,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.nn.functional.interpolate(\n",
    "            x, (x.shape[-2] * self.upscale_factor, x.shape[-1] * self.upscale_factor), mode=\"bilinear\"\n",
    "        )\n",
    "        x = self.model(x)\n",
    "        x = torch.nn.functional.interpolate(\n",
    "            x, (x.shape[-2] // self.upscale_factor, x.shape[-1] // self.upscale_factor), mode=\"bilinear\"\n",
    "        )\n",
    "        return x\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a26ca64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-11T18:07:37.149504Z",
     "iopub.status.busy": "2024-02-11T18:07:37.149186Z",
     "iopub.status.idle": "2024-02-11T18:07:37.167001Z",
     "shell.execute_reply": "2024-02-11T18:07:37.166194Z"
    },
    "papermill": {
     "duration": 0.027271,
     "end_time": "2024-02-11T18:07:37.168988",
     "exception": false,
     "start_time": "2024-02-11T18:07:37.141717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Dataset2DMultiPlanesTest(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        full_image,\n",
    "        crop_size,\n",
    "        overlap_size,\n",
    "        planes,\n",
    "        transform=None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        step_size = crop_size - overlap_size\n",
    "        self.crop_size = crop_size\n",
    "        self.image = full_image\n",
    "         \n",
    "        self.depth, self.height, self.width = self.image.shape\n",
    "        \n",
    "        #calculate XY coordinates\n",
    "        xy_coordinates = []\n",
    "        if 'xy' in planes:\n",
    "            for z in range(self.depth):\n",
    "                for y in range(0, self.height - step_size, step_size):\n",
    "                    for x in range(0, self.width - step_size, step_size):\n",
    "                        crop_end_y = min(y + crop_size, self.height)\n",
    "                        crop_end_x = min(x + crop_size, self.width)\n",
    "\n",
    "                        xy_coordinates.append((z, z+1, y, crop_end_y, x, crop_end_x))\n",
    "\n",
    "        # calculate XZ coordinates\n",
    "        xz_coordinates = []\n",
    "        if 'xz' in planes:\n",
    "            for z in range(0, self.depth - step_size, step_size):\n",
    "                for y in range(self.height):\n",
    "                    for x in range(0, self.width - step_size, step_size):\n",
    "                        crop_end_z = min(z + crop_size, self.depth)\n",
    "                        crop_end_x = min(x + crop_size, self.width)\n",
    "\n",
    "                        xz_coordinates.append((z, crop_end_z, y, y+1, x, crop_end_x))\n",
    "\n",
    "        # calculate YZ coordinates\n",
    "        yz_coordinates = []\n",
    "        if 'yz' in planes:\n",
    "            for z in range(0, self.depth - step_size, step_size):\n",
    "                for y in range(0, self.height - step_size, step_size):\n",
    "                    for x in range(self.width):\n",
    "                        crop_end_z = min(z + crop_size, self.depth)\n",
    "                        crop_end_y = min(y + crop_size, self.height)\n",
    "\n",
    "                        yz_coordinates.append((z, crop_end_z, y, crop_end_y, x, x+1))\n",
    "\n",
    "        print(f'num xy slices: {len(xy_coordinates)} num xz slices: {len(xz_coordinates)} num yz slices: {len(yz_coordinates)}')\n",
    "        self.coordinates = xy_coordinates + xz_coordinates + yz_coordinates\n",
    "        print(f'total num of coordinates across 3 planes: {len(self.coordinates)}')\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.coordinates)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        coordinates = self.coordinates[idx]\n",
    "        z1, z2, y1, y2, x1, x2 = coordinates\n",
    "        \n",
    "        image_crop = self.image[z1:z2, y1:y2, x1:x2].copy().squeeze()\n",
    "        \n",
    "        height_pad_before = height_pad_after = width_pad_before = width_pad_after = 0\n",
    "        if image_crop.shape[0] != self.crop_size:\n",
    "            height_pad_size = self.crop_size - image_crop.shape[0]\n",
    "            height_pad_before = height_pad_size // 2\n",
    "            height_pad_after = height_pad_size - height_pad_before\n",
    "\n",
    "        if image_crop.shape[1] != self.crop_size:\n",
    "            width_pad_size = self.crop_size - image_crop.shape[1]\n",
    "            width_pad_before = width_pad_size // 2\n",
    "            width_pad_after = width_pad_size - width_pad_before\n",
    "            \n",
    "        image_crop = np.pad(image_crop, ((height_pad_before, height_pad_after), (width_pad_before, width_pad_after)), mode=\"constant\", constant_values=0)        \n",
    "               \n",
    "        if self.transform:\n",
    "            sample = self.transform(image=image_crop)\n",
    "            image_crop = sample['image']\n",
    "\n",
    "        image_mean = torch.mean(image_crop.float())\n",
    "        image_std = torch.std(image_crop.float())\n",
    "\n",
    "        image_crop = (image_crop - image_mean) / (image_std + 1e-4)\n",
    "        \n",
    "        return image_crop, torch.tensor([z1, z2, y1, y2, x1, x2]), torch.tensor([height_pad_before, height_pad_after, width_pad_before, width_pad_after])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa2ca679",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-11T18:07:37.182960Z",
     "iopub.status.busy": "2024-02-11T18:07:37.182323Z",
     "iopub.status.idle": "2024-02-11T18:07:37.188095Z",
     "shell.execute_reply": "2024-02-11T18:07:37.187284Z"
    },
    "papermill": {
     "duration": 0.014619,
     "end_time": "2024-02-11T18:07:37.189946",
     "exception": false,
     "start_time": "2024-02-11T18:07:37.175327",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_dataset(dataset_root):\n",
    "    paths = sorted(glob(f'{dataset_root}/*.tif'))\n",
    "    height, width = tifffile.memmap(paths[0], mode='r').shape\n",
    "    \n",
    "    full_image = np.zeros((len(paths), height, width), dtype=np.uint8)\n",
    "    \n",
    "    for path_index, path in enumerate(paths):\n",
    "        full_image[path_index] = (tifffile.imread(path) / 256).astype(np.uint8)\n",
    "    \n",
    "    return full_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5e8661e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-11T18:07:37.203747Z",
     "iopub.status.busy": "2024-02-11T18:07:37.203447Z",
     "iopub.status.idle": "2024-02-11T18:07:37.221366Z",
     "shell.execute_reply": "2024-02-11T18:07:37.220631Z"
    },
    "papermill": {
     "duration": 0.027018,
     "end_time": "2024-02-11T18:07:37.223250",
     "exception": false,
     "start_time": "2024-02-11T18:07:37.196232",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(\n",
    "    batch_size,\n",
    "    num_workers,\n",
    "    dataset_params,\n",
    "    model_name,\n",
    "    model_params,\n",
    "    test_kidney=None,\n",
    "):  \n",
    "\n",
    "    if model_name == 'unet':\n",
    "        model = smp.Unet(\n",
    "            encoder_name=model_params['encoder_name'],\n",
    "            decoder_use_batchnorm=model_params['decoder_use_batchnorm'],\n",
    "            in_channels=1,\n",
    "            classes=1,\n",
    "            encoder_weights=None,\n",
    "        )\n",
    "    elif model_name == 'unet_upscale':\n",
    "        model = UnetUpscale(\n",
    "            encoder_name=model_params['encoder_name'],\n",
    "            decoder_use_batchnorm=model_params['decoder_use_batchnorm'],\n",
    "            upscale_factor=model_params['upscale_factor'],\n",
    "            in_channels=1,\n",
    "            classes=1,\n",
    "            encoder_weights=None,\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError('Wrong model_name')\n",
    "\n",
    "\n",
    "    checkpoint = torch.load(model_params['checkpoint_path'], map_location='cpu')\n",
    "\n",
    "    model.load_state_dict(checkpoint['model'], strict=True)\n",
    "    model.cuda().eval();\n",
    "\n",
    "    transform = A.Compose(\n",
    "        [\n",
    "            AT.ToTensorV2(),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    dataset = Dataset2DMultiPlanesTest(\n",
    "        full_image=test_kidney,\n",
    "        crop_size=dataset_params['crop_size'],\n",
    "        overlap_size=dataset_params['overlap_size'],\n",
    "        planes=dataset_params['planes'],\n",
    "        transform=transform,\n",
    "    )\n",
    "\n",
    "    loader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "        batch_size=batch_size,\n",
    "        pin_memory=True,\n",
    "        num_workers=num_workers,\n",
    "    )\n",
    "\n",
    "\n",
    "    y_pred_shape = (loader.dataset.depth, loader.dataset.height, loader.dataset.width)\n",
    "    y_pred = torch.zeros(y_pred_shape, dtype=torch.float16)\n",
    "    y_stats = torch.zeros(y_pred_shape, dtype=torch.uint8)\n",
    "\n",
    "    for (input, coordinates, paddings) in (tqdm(loader)):\n",
    "        input = input.cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            with torch.cuda.amp.autocast(enabled=True):\n",
    "                preds = model(input)\n",
    "\n",
    "                for coordinates_sample, paddings_sample, preds_sample in zip(coordinates, paddings, preds):\n",
    "                    z1, z2, y1, y2, x1, x2 = coordinates_sample\n",
    "                    \n",
    "                    height_pad_before, height_pad_after, width_pad_before, width_pad_after = paddings_sample\n",
    "                    if height_pad_before:\n",
    "                        preds_sample = preds_sample[:, height_pad_before:, :]\n",
    "                    if height_pad_after:\n",
    "                        preds_sample = preds_sample[:, :-height_pad_after, :]\n",
    "                    if width_pad_before:\n",
    "                        preds_sample = preds_sample[:, :, width_pad_before:]\n",
    "                    if width_pad_after:\n",
    "                        preds_sample = preds_sample[:, :, :-width_pad_after]\n",
    "\n",
    "                    slice_shape = y_pred[z1:z2, y1:y2, x1:x2].shape\n",
    "\n",
    "                    y_pred[z1:z2, y1:y2, x1:x2] += preds_sample.view(slice_shape).cpu()\n",
    "                    y_stats[z1:z2, y1:y2, x1:x2] += 1\n",
    "\n",
    "\n",
    "    y_pred /= y_stats\n",
    "\n",
    "    del model, y_stats\n",
    "    gc.collect()\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "def rle_encode(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels = img.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e72700e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-11T18:07:37.236365Z",
     "iopub.status.busy": "2024-02-11T18:07:37.236124Z",
     "iopub.status.idle": "2024-02-11T18:07:37.239888Z",
     "shell.execute_reply": "2024-02-11T18:07:37.239048Z"
    },
    "papermill": {
     "duration": 0.012419,
     "end_time": "2024-02-11T18:07:37.241785",
     "exception": false,
     "start_time": "2024-02-11T18:07:37.229366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "th = 0.025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9201e27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-11T18:07:37.255593Z",
     "iopub.status.busy": "2024-02-11T18:07:37.255293Z",
     "iopub.status.idle": "2024-02-11T18:07:37.260258Z",
     "shell.execute_reply": "2024-02-11T18:07:37.259505Z"
    },
    "papermill": {
     "duration": 0.013913,
     "end_time": "2024-02-11T18:07:37.262162",
     "exception": false,
     "start_time": "2024-02-11T18:07:37.248249",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model1 = {\n",
    "    'batch_size': 2,\n",
    "    'num_workers': 2,\n",
    "    'dataset_params' : {\n",
    "            'crop_size': 512,\n",
    "            'overlap_size': 256,\n",
    "            'planes': ['xy', 'xz', 'yz'],\n",
    "        },\n",
    "    'model_name': 'unet',\n",
    "    'model_params':\n",
    "        {\n",
    "            'encoder_name': 'tu-maxvit_base_tf_512.in21k_ft_in1k',\n",
    "            'decoder_use_batchnorm': False,\n",
    "            'checkpoint_path': './weights/maxvit_base.pt/epoch_33_surface_dice_at_mean_0.8023.pt',\n",
    "        },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adc44831",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-11T18:07:37.276554Z",
     "iopub.status.busy": "2024-02-11T18:07:37.275837Z",
     "iopub.status.idle": "2024-02-11T18:07:37.281093Z",
     "shell.execute_reply": "2024-02-11T18:07:37.280279Z"
    },
    "papermill": {
     "duration": 0.014416,
     "end_time": "2024-02-11T18:07:37.283082",
     "exception": false,
     "start_time": "2024-02-11T18:07:37.268666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model2 = {\n",
    "    'batch_size': 4,\n",
    "    'num_workers': 2,\n",
    "    'dataset_params' : {\n",
    "            'crop_size': 512,\n",
    "            'overlap_size': 256,\n",
    "            'planes': ['xy', 'xz', 'yz'],\n",
    "        },\n",
    "    'model_name': 'unet_upscale',\n",
    "    'model_params':\n",
    "        {\n",
    "            'encoder_name': 'tu-tf_efficientnetv2_s.in21k_ft_in1k',\n",
    "            'decoder_use_batchnorm': False,\n",
    "            'checkpoint_path': './weights/effnet_v2_m.pt/epoch_23_surface_dice_at_mean_0.8133.pt',\n",
    "            'upscale_factor': 2,\n",
    "        },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b240552f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-11T18:07:37.297194Z",
     "iopub.status.busy": "2024-02-11T18:07:37.296830Z",
     "iopub.status.idle": "2024-02-11T18:07:37.302230Z",
     "shell.execute_reply": "2024-02-11T18:07:37.301318Z"
    },
    "papermill": {
     "duration": 0.014475,
     "end_time": "2024-02-11T18:07:37.304223",
     "exception": false,
     "start_time": "2024-02-11T18:07:37.289748",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model3 = {\n",
    "    'batch_size': 2,\n",
    "    'num_workers': 2,\n",
    "    'dataset_params' : {\n",
    "            'crop_size': 512,\n",
    "            'overlap_size': 256,\n",
    "            'planes': ['xy', 'xz', 'yz'],\n",
    "        },\n",
    "    'model_name': 'unet_upscale',\n",
    "    'model_params':\n",
    "        {\n",
    "            'encoder_name': 'tu-dpn68b',\n",
    "            'decoder_use_batchnorm': False,\n",
    "            'checkpoint_path': './weights/dpn_68.pt/epoch_38_surface_dice_at_mean_0.80779.pt',\n",
    "            'upscale_factor': 2,\n",
    "        },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3633cac7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-11T18:07:37.318248Z",
     "iopub.status.busy": "2024-02-11T18:07:37.317725Z",
     "iopub.status.idle": "2024-02-11T18:07:37.321769Z",
     "shell.execute_reply": "2024-02-11T18:07:37.320934Z"
    },
    "papermill": {
     "duration": 0.013106,
     "end_time": "2024-02-11T18:07:37.323718",
     "exception": false,
     "start_time": "2024-02-11T18:07:37.310612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "models = [model1, model2, model3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "582e63a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-11T18:07:37.337687Z",
     "iopub.status.busy": "2024-02-11T18:07:37.337404Z",
     "iopub.status.idle": "2024-02-11T18:08:28.344121Z",
     "shell.execute_reply": "2024-02-11T18:08:28.343247Z"
    },
    "papermill": {
     "duration": 51.016426,
     "end_time": "2024-02-11T18:08:28.346600",
     "exception": false,
     "start_time": "2024-02-11T18:07:37.330174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num xy slices: 18960 num xz slices: 15552 num yz slices: 15850\n",
      "total num of coordinates across 3 planes: 50362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25181/25181 [25:47<00:00, 16.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num xy slices: 18960 num xz slices: 15552 num yz slices: 15850\n",
      "total num of coordinates across 3 planes: 50362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12591/12591 [12:58<00:00, 16.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num xy slices: 18960 num xz slices: 15552 num yz slices: 15850\n",
      "total num of coordinates across 3 planes: 50362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25181/25181 [14:43<00:00, 28.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num xy slices: 30360 num xz slices: 23940 num yz slices: 23970\n",
      "total num of coordinates across 3 planes: 78270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39135/39135 [39:16<00:00, 16.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num xy slices: 30360 num xz slices: 23940 num yz slices: 23970\n",
      "total num of coordinates across 3 planes: 78270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19568/19568 [20:02<00:00, 16.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num xy slices: 30360 num xz slices: 23940 num yz slices: 23970\n",
      "total num of coordinates across 3 planes: 78270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39135/39135 [22:29<00:00, 29.00it/s]\n"
     ]
    }
   ],
   "source": [
    "ids, rles = [], []\n",
    "\n",
    "for test_kidney in [6,5]:\n",
    "    images_paths = sorted(glob(f'/teradata/hra_data/k4_data/competition-data/test/kidney_{test_kidney}/images/*.tif')) \n",
    "    test_kidney_image = create_dataset(\n",
    "        dataset_root=f'/teradata/hra_data/k4_data/competition-data/test/kidney_{test_kidney}/images/'\n",
    "    )\n",
    "\n",
    "    if test_kidney == 6:\n",
    "        private_res = 63.08\n",
    "        public_res = 50.0\n",
    "\n",
    "        scale = private_res / public_res\n",
    "\n",
    "        d_original, h_original, w_original = test_kidney_image.shape\n",
    "        test_kidney_image = torch.tensor(test_kidney_image).view(1, 1, d_original, h_original, w_original)\n",
    "        test_kidney_image = test_kidney_image.to(dtype=torch.float32)\n",
    "        test_kidney_image = torch.nn.functional.interpolate(test_kidney_image, (\n",
    "            int(d_original*scale),\n",
    "            int(h_original*scale),\n",
    "            int(w_original*scale),\n",
    "        ), mode='trilinear').squeeze().numpy()\n",
    "\n",
    "    for model_index, model in enumerate(models):\n",
    "        preds = predict(\n",
    "            **model,\n",
    "            test_kidney=test_kidney_image,\n",
    "        )\n",
    "\n",
    "        if model_index == 0:\n",
    "            preds_ensemble = preds\n",
    "        else:\n",
    "            preds_ensemble += preds\n",
    "\n",
    "        del preds\n",
    "        gc.collect()\n",
    "\n",
    "    del test_kidney_image\n",
    "    gc.collect()\n",
    "\n",
    "    preds_ensemble /= len(models)\n",
    "    if test_kidney == 6:\n",
    "        d_preds, h_preds, w_preds = preds_ensemble.shape \n",
    "        preds_ensemble = preds_ensemble.view(1, 1, d_preds, h_preds, w_preds)\n",
    "        preds_ensemble = preds_ensemble.to(dtype=torch.float32)\n",
    "\n",
    "        preds_ensemble = torch.nn.functional.interpolate(preds_ensemble, (\n",
    "            d_original,\n",
    "            h_original,\n",
    "            w_original,\n",
    "        ), mode='trilinear').squeeze()\n",
    "\n",
    "    preds_ensemble_th = torch.sigmoid(preds_ensemble.cuda()).cpu() > th\n",
    "    for pred_index, pred in enumerate(preds_ensemble_th):\n",
    "        ids.append(f'kidney_{test_kidney}_{images_paths[pred_index].split(\"/\")[-1].split(\".\")[0]}')\n",
    "        rle = rle_encode(pred)\n",
    "        if rle == '':\n",
    "            rle = '1 0'\n",
    "        rles.append(rle)\n",
    "\n",
    "    del preds_ensemble, preds_ensemble_th\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': ids,\n",
    "    'rle': rles,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26471ce5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-11T18:08:28.386777Z",
     "iopub.status.busy": "2024-02-11T18:08:28.386402Z",
     "iopub.status.idle": "2024-02-11T18:08:28.395066Z",
     "shell.execute_reply": "2024-02-11T18:08:28.394404Z"
    },
    "papermill": {
     "duration": 0.030821,
     "end_time": "2024-02-11T18:08:28.396926",
     "exception": false,
     "start_time": "2024-02-11T18:08:28.366105",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission.to_csv('submission-validation.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb4f21ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numba\n",
      "  Using cached numba-0.59.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
      "Collecting llvmlite<0.43,>=0.42.0dev0 (from numba)\n",
      "  Using cached llvmlite-0.42.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: numpy<1.27,>=1.22 in /u/yashjain/anaconda3/envs/k4-team-5-env/lib/python3.10/site-packages (from numba) (1.26.4)\n",
      "Using cached numba-0.59.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n",
      "Using cached llvmlite-0.42.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.8 MB)\n",
      "Installing collected packages: llvmlite, numba\n",
      "Successfully installed llvmlite-0.42.0 numba-0.59.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41f0902e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os \n",
    "sys.path.append(f'{os.getcwd()}/sennet-metrics')\n",
    "sys.path.append(f'{os.getcwd()}/sennet-metrics/src')\n",
    "\n",
    "from sennet_metrices import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fb26370b",
   "metadata": {
    "papermill": {
     "duration": 0.019416,
     "end_time": "2024-02-11T18:08:28.435486",
     "exception": false,
     "start_time": "2024-02-11T18:08:28.416070",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kidney_5_submit_df shape: (1012, 2)\n",
      "kidney_6_submit_df shape: (501, 2)\n",
      "kidney_5_label_df shape: (1012, 7)\n",
      "kidney_6_label_df shape: (501, 7)\n",
      "Surface dice for public test (kidney_5) set is: 0.8855258822441101\n",
      "Surface dice for private test (kidney_6) set is: 0.691794216632843\n"
     ]
    }
   ],
   "source": [
    "# Compute competition metric.\n",
    "\n",
    "submit_df = pd.read_csv('submission-validation.csv')\n",
    "label_df = pd.read_csv('/teradata/hra_data/k4_data/competition-data/solution.csv')\n",
    "\n",
    "# Check the id column of the dataframe and separate rows into two dataframes based on if the values contains \"kidney_5\" or \"kidney_6\".\n",
    "kidney_5_submit_df = submit_df[submit_df['id'].str.contains('kidney_5')]\n",
    "kidney_6_submit_df = submit_df[submit_df['id'].str.contains('kidney_6')]\n",
    "print(f'kidney_5_submit_df shape: {kidney_5_submit_df.shape}')\n",
    "print(f'kidney_6_submit_df shape: {kidney_6_submit_df.shape}')\n",
    "\n",
    "kidney_5_label_df = label_df[label_df['id'].str.contains('kidney_5')]\n",
    "kidney_6_label_df = label_df[label_df['id'].str.contains('kidney_6')]\n",
    "print(f'kidney_5_label_df shape: {kidney_5_label_df.shape}')\n",
    "print(f'kidney_6_label_df shape: {kidney_6_label_df.shape}')\n",
    "\n",
    "kidney_5_submit_df.reset_index(inplace=True)\n",
    "kidney_6_submit_df.reset_index(inplace=True)\n",
    "kidney_5_label_df.reset_index(inplace=True)\n",
    "kidney_6_label_df.reset_index(inplace=True)\n",
    "\n",
    "## -------------- Surface Dice --------------\n",
    "surface_dice_kidney_5 = compute_surface_dice_score(kidney_5_submit_df, kidney_5_label_df)\n",
    "print(f'Surface dice for public test (kidney_5) set is: {surface_dice_kidney_5}')\n",
    "\n",
    "surface_dice_kidney_6 = compute_surface_dice_score(kidney_6_submit_df, kidney_6_label_df)\n",
    "print(f'Surface dice for private test (kidney_6) set is: {surface_dice_kidney_6}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d938683",
   "metadata": {
    "papermill": {
     "duration": 0.018714,
     "end_time": "2024-02-11T18:08:28.511104",
     "exception": false,
     "start_time": "2024-02-11T18:08:28.492390",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 6962461,
     "sourceId": 61446,
     "sourceType": "competition"
    },
    {
     "datasetId": 4429227,
     "sourceId": 7607219,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 158724263,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30636,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 101.570504,
   "end_time": "2024-02-11T18:08:30.792585",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-02-11T18:06:49.222081",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
