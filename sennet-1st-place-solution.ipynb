{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7379d7a1",
   "metadata": {
    "papermill": {
     "duration": 0.005193,
     "end_time": "2024-02-12T16:10:55.687744",
     "exception": false,
     "start_time": "2024-02-12T16:10:55.682551",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fae0999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting albumentations==1.3.1 (from -r requirements.txt (line 1))\n",
      "  Using cached albumentations-1.3.1-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting colorama==0.4.6 (from -r requirements.txt (line 2))\n",
      "  Using cached colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting efficientnet_pytorch==0.7.1 (from -r requirements.txt (line 3))\n",
      "  Using cached efficientnet_pytorch-0.7.1-py3-none-any.whl\n",
      "Collecting einops==0.7.0 (from -r requirements.txt (line 4))\n",
      "  Downloading einops-0.7.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting Geometry3D==0.2.4 (from -r requirements.txt (line 5))\n",
      "  Downloading Geometry3D-0.2.4.tar.gz (24 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting loguru==0.7.2 (from -r requirements.txt (line 6))\n",
      "  Downloading loguru-0.7.2-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting matplotlib==3.8.2 (from -r requirements.txt (line 7))\n",
      "  Using cached matplotlib-3.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "Collecting numba==0.58.1 (from -r requirements.txt (line 8))\n",
      "  Downloading numba-0.58.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
      "Collecting numpy==1.26.4 (from -r requirements.txt (line 9))\n",
      "  Using cached numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting opencv_python==4.8.1.78 (from -r requirements.txt (line 10))\n",
      "  Downloading opencv_python-4.8.1.78-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Collecting pandas==2.2.0 (from -r requirements.txt (line 11))\n",
      "  Downloading pandas-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Collecting Pillow==10.2.0 (from -r requirements.txt (line 12))\n",
      "  Using cached pillow-10.2.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
      "Collecting pretrainedmodels==0.7.4 (from -r requirements.txt (line 13))\n",
      "  Using cached pretrainedmodels-0.7.4-py3-none-any.whl\n",
      "Collecting scipy==1.12.0 (from -r requirements.txt (line 14))\n",
      "  Using cached scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Collecting timm==0.9.10 (from -r requirements.txt (line 15))\n",
      "  Downloading timm-0.9.10-py3-none-any.whl.metadata (59 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.8/59.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting torch==2.0.1 (from -r requirements.txt (line 16))\n",
      "  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\n",
      "Collecting torchvision==0.15.2 (from -r requirements.txt (line 17))\n",
      "  Downloading torchvision-0.15.2-cp310-cp310-manylinux1_x86_64.whl.metadata (11 kB)\n",
      "Collecting tqdm==4.66.1 (from -r requirements.txt (line 18))\n",
      "  Using cached tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting transformers==4.35.2 (from -r requirements.txt (line 19))\n",
      "  Downloading transformers-4.35.2-py3-none-any.whl.metadata (123 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.5/123.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting scikit-image>=0.16.1 (from albumentations==1.3.1->-r requirements.txt (line 1))\n",
      "  Using cached scikit_image-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting PyYAML (from albumentations==1.3.1->-r requirements.txt (line 1))\n",
      "  Using cached PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting qudida>=0.0.4 (from albumentations==1.3.1->-r requirements.txt (line 1))\n",
      "  Using cached qudida-0.0.4-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opencv-python-headless>=4.1.1 (from albumentations==1.3.1->-r requirements.txt (line 1))\n",
      "  Using cached opencv_python_headless-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib==3.8.2->-r requirements.txt (line 7))\n",
      "  Using cached contourpy-1.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib==3.8.2->-r requirements.txt (line 7))\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib==3.8.2->-r requirements.txt (line 7))\n",
      "  Downloading fonttools-4.50.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (159 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.4/159.4 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib==3.8.2->-r requirements.txt (line 7))\n",
      "  Using cached kiwisolver-1.4.5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /u/yashjain/anaconda3/envs/k4-team1-env/lib/python3.10/site-packages (from matplotlib==3.8.2->-r requirements.txt (line 7)) (24.0)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib==3.8.2->-r requirements.txt (line 7))\n",
      "  Using cached pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /u/yashjain/anaconda3/envs/k4-team1-env/lib/python3.10/site-packages (from matplotlib==3.8.2->-r requirements.txt (line 7)) (2.9.0)\n",
      "Collecting llvmlite<0.42,>=0.41.0dev0 (from numba==0.58.1->-r requirements.txt (line 8))\n",
      "  Downloading llvmlite-0.41.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "Collecting pytz>=2020.1 (from pandas==2.2.0->-r requirements.txt (line 11))\n",
      "  Using cached pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas==2.2.0->-r requirements.txt (line 11))\n",
      "  Using cached tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting munch (from pretrainedmodels==0.7.4->-r requirements.txt (line 13))\n",
      "  Using cached munch-4.0.0-py2.py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting huggingface-hub (from timm==0.9.10->-r requirements.txt (line 15))\n",
      "  Using cached huggingface_hub-0.21.4-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting safetensors (from timm==0.9.10->-r requirements.txt (line 15))\n",
      "  Using cached safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting filelock (from torch==2.0.1->-r requirements.txt (line 16))\n",
      "  Using cached filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: typing-extensions in /u/yashjain/anaconda3/envs/k4-team1-env/lib/python3.10/site-packages (from torch==2.0.1->-r requirements.txt (line 16)) (4.10.0)\n",
      "Collecting sympy (from torch==2.0.1->-r requirements.txt (line 16))\n",
      "  Using cached sympy-1.12-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch==2.0.1->-r requirements.txt (line 16))\n",
      "  Using cached networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting jinja2 (from torch==2.0.1->-r requirements.txt (line 16))\n",
      "  Using cached Jinja2-3.1.3-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.1->-r requirements.txt (line 16))\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.1->-r requirements.txt (line 16))\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.1->-r requirements.txt (line 16))\n",
      "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.1->-r requirements.txt (line 16))\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.1->-r requirements.txt (line 16))\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.1->-r requirements.txt (line 16))\n",
      "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.1->-r requirements.txt (line 16))\n",
      "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.1->-r requirements.txt (line 16))\n",
      "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.1->-r requirements.txt (line 16))\n",
      "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.1->-r requirements.txt (line 16))\n",
      "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.1->-r requirements.txt (line 16))\n",
      "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==2.0.0 (from torch==2.0.1->-r requirements.txt (line 16))\n",
      "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n",
      "Collecting requests (from torchvision==0.15.2->-r requirements.txt (line 17))\n",
      "  Using cached requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers==4.35.2->-r requirements.txt (line 19))\n",
      "  Downloading regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers<0.19,>=0.14 (from transformers==4.35.2->-r requirements.txt (line 19))\n",
      "  Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: setuptools in /u/yashjain/anaconda3/envs/k4-team1-env/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->-r requirements.txt (line 16)) (68.2.2)\n",
      "Requirement already satisfied: wheel in /u/yashjain/anaconda3/envs/k4-team1-env/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->-r requirements.txt (line 16)) (0.41.2)\n",
      "Collecting cmake (from triton==2.0.0->torch==2.0.1->-r requirements.txt (line 16))\n",
      "  Downloading cmake-3.28.3-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.3 kB)\n",
      "Collecting lit (from triton==2.0.0->torch==2.0.1->-r requirements.txt (line 16))\n",
      "  Downloading lit-18.1.1.tar.gz (161 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.1/161.1 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting fsspec>=2023.5.0 (from huggingface-hub->timm==0.9.10->-r requirements.txt (line 15))\n",
      "  Downloading fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: six>=1.5 in /u/yashjain/anaconda3/envs/k4-team1-env/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib==3.8.2->-r requirements.txt (line 7)) (1.16.0)\n",
      "Collecting scikit-learn>=0.19.1 (from qudida>=0.0.4->albumentations==1.3.1->-r requirements.txt (line 1))\n",
      "  Using cached scikit_learn-1.4.1.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting imageio>=2.27 (from scikit-image>=0.16.1->albumentations==1.3.1->-r requirements.txt (line 1))\n",
      "  Using cached imageio-2.34.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image>=0.16.1->albumentations==1.3.1->-r requirements.txt (line 1))\n",
      "  Using cached tifffile-2024.2.12-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting lazy_loader>=0.3 (from scikit-image>=0.16.1->albumentations==1.3.1->-r requirements.txt (line 1))\n",
      "  Using cached lazy_loader-0.3-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch==2.0.1->-r requirements.txt (line 16))\n",
      "  Using cached MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->torchvision==0.15.2->-r requirements.txt (line 17))\n",
      "  Using cached charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->torchvision==0.15.2->-r requirements.txt (line 17))\n",
      "  Using cached idna-3.6-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->torchvision==0.15.2->-r requirements.txt (line 17))\n",
      "  Using cached urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->torchvision==0.15.2->-r requirements.txt (line 17))\n",
      "  Using cached certifi-2024.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting mpmath>=0.19 (from sympy->torch==2.0.1->-r requirements.txt (line 16))\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.3.1->-r requirements.txt (line 1))\n",
      "  Using cached joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.3.1->-r requirements.txt (line 1))\n",
      "  Downloading threadpoolctl-3.4.0-py3-none-any.whl.metadata (13 kB)\n",
      "Using cached albumentations-1.3.1-py3-none-any.whl (125 kB)\n",
      "Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading loguru-0.7.2-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached matplotlib-3.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
      "Downloading numba-0.58.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "Downloading opencv_python-4.8.1.78-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hUsing cached pillow-10.2.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "Using cached scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\n",
      "Downloading timm-0.9.10-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.15.2-cp310-cp310-manylinux1_x86_64.whl (6.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "Downloading transformers-4.35.2-py3-none-any.whl (7.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached contourpy-1.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (310 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.50.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached huggingface_hub-0.21.4-py3-none-any.whl (346 kB)\n",
      "Using cached kiwisolver-1.4.5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "Downloading llvmlite-0.41.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached opencv_python_headless-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.6 MB)\n",
      "Using cached pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
      "Using cached pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Using cached PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (705 kB)\n",
      "Using cached qudida-0.0.4-py3-none-any.whl (3.5 kB)\n",
      "Downloading regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m774.0/774.0 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Using cached scikit_image-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.7 MB)\n",
      "Using cached networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Using cached filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Using cached Jinja2-3.1.3-py3-none-any.whl (133 kB)\n",
      "Using cached munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\n",
      "Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Using cached certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
      "Using cached charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
      "Downloading fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.0/172.0 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached idna-3.6-py3-none-any.whl (61 kB)\n",
      "Using cached imageio-2.34.0-py3-none-any.whl (313 kB)\n",
      "Using cached lazy_loader-0.3-py3-none-any.whl (9.1 kB)\n",
      "Using cached MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached scikit_learn-1.4.1.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
      "Using cached tifffile-2024.2.12-py3-none-any.whl (224 kB)\n",
      "Using cached urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "Downloading cmake-3.28.3-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (26.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.3/26.3 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "Downloading threadpoolctl-3.4.0-py3-none-any.whl (17 kB)\n",
      "Building wheels for collected packages: Geometry3D, lit\n",
      "  Building wheel for Geometry3D (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for Geometry3D: filename=Geometry3D-0.2.4-py3-none-any.whl size=35779 sha256=b8d57ec7d9749f55df88e0519dfaa5658d3c1d479c6017a606575612a399abb4\n",
      "  Stored in directory: /u/yashjain/.cache/pip/wheels/91/e8/e7/e8e2e819725267334c5f06841e80fd18d1d51d717b669481e2\n",
      "  Building wheel for lit (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lit: filename=lit-18.1.1-py3-none-any.whl size=96363 sha256=82ad2fcfd0b1aae4fbef26111af846f0002bc595f4bb93ae5a715cbf75f0a799\n",
      "  Stored in directory: /u/yashjain/.cache/pip/wheels/1d/74/6b/88e95944e9f9078f1dc1c0f634a542efb4d26ecae6000ca8cf\n",
      "Successfully built Geometry3D lit\n",
      "Installing collected packages: pytz, mpmath, lit, Geometry3D, cmake, urllib3, tzdata, tqdm, threadpoolctl, sympy, safetensors, regex, PyYAML, pyparsing, Pillow, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, numpy, networkx, munch, MarkupSafe, loguru, llvmlite, lazy_loader, kiwisolver, joblib, idna, fsspec, fonttools, filelock, einops, cycler, colorama, charset-normalizer, certifi, tifffile, scipy, requests, pandas, opencv-python-headless, opencv_python, nvidia-cusolver-cu11, nvidia-cudnn-cu11, numba, jinja2, imageio, contourpy, scikit-learn, scikit-image, matplotlib, huggingface-hub, tokenizers, qudida, transformers, albumentations, triton, torch, torchvision, timm, pretrainedmodels, efficientnet_pytorch\n",
      "Successfully installed Geometry3D-0.2.4 MarkupSafe-2.1.5 Pillow-10.2.0 PyYAML-6.0.1 albumentations-1.3.1 certifi-2024.2.2 charset-normalizer-3.3.2 cmake-3.28.3 colorama-0.4.6 contourpy-1.2.0 cycler-0.12.1 efficientnet_pytorch-0.7.1 einops-0.7.0 filelock-3.13.1 fonttools-4.50.0 fsspec-2024.3.1 huggingface-hub-0.21.4 idna-3.6 imageio-2.34.0 jinja2-3.1.3 joblib-1.3.2 kiwisolver-1.4.5 lazy_loader-0.3 lit-18.1.1 llvmlite-0.41.1 loguru-0.7.2 matplotlib-3.8.2 mpmath-1.3.0 munch-4.0.0 networkx-3.2.1 numba-0.58.1 numpy-1.26.4 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 opencv-python-headless-4.9.0.80 opencv_python-4.8.1.78 pandas-2.2.0 pretrainedmodels-0.7.4 pyparsing-3.1.2 pytz-2024.1 qudida-0.0.4 regex-2023.12.25 requests-2.31.0 safetensors-0.4.2 scikit-image-0.22.0 scikit-learn-1.4.1.post1 scipy-1.12.0 sympy-1.12 threadpoolctl-3.4.0 tifffile-2024.2.12 timm-0.9.10 tokenizers-0.15.2 torch-2.0.1 torchvision-0.15.2 tqdm-4.66.1 transformers-4.35.2 triton-2.0.0 tzdata-2024.1 urllib3-2.2.1\n"
     ]
    }
   ],
   "source": [
    "# Before this, make a new conda environment woth Python 3.10\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a42db2d",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-02-12T16:10:55.698703Z",
     "iopub.status.busy": "2024-02-12T16:10:55.698353Z",
     "iopub.status.idle": "2024-02-12T16:15:54.155093Z",
     "shell.execute_reply": "2024-02-12T16:15:54.153796Z"
    },
    "papermill": {
     "duration": 298.465396,
     "end_time": "2024-02-12T16:15:54.158026",
     "exception": false,
     "start_time": "2024-02-12T16:10:55.692630",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: triton in /u/yashjain/anaconda3/envs/k4-team1-env/lib/python3.10/site-packages (2.2.0)\n",
      "Requirement already satisfied: filelock in /u/yashjain/anaconda3/envs/k4-team1-env/lib/python3.10/site-packages (from triton) (3.13.1)\n"
     ]
    }
   ],
   "source": [
    "# !pip install -q --no-index --find-links ./pip-download-for-segmentation-models-pytorch/triton-wheel ./pip-download-for-segmentation-models-pytorch/torch-2.1.1+cu118-cp310-cp310-linux_x86_64.whl\n",
    "!pip install triton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6916b13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting connected-components-3d\n",
      "  Downloading connected_components_3d-3.12.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (29 kB)\n",
      "Requirement already satisfied: numpy in /u/yashjain/anaconda3/envs/k4-team1-env/lib/python3.10/site-packages (from connected-components-3d) (1.26.4)\n",
      "Downloading connected_components_3d-3.12.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: connected-components-3d\n",
      "Successfully installed connected-components-3d-3.12.4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# !pip install -q ./pip-download-for-segmentation-models-pytorch/connected_components_3d-3.12.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
    "!pip install connected-components-3d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8fe3a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: timm==0.9.10 in /u/yashjain/anaconda3/envs/k4-team1-env/lib/python3.10/site-packages (0.9.10)\n",
      "Requirement already satisfied: torch>=1.7 in /u/yashjain/anaconda3/envs/k4-team1-env/lib/python3.10/site-packages (from timm==0.9.10) (2.0.1)\n",
      "Requirement already satisfied: torchvision in /u/yashjain/anaconda3/envs/k4-team1-env/lib/python3.10/site-packages (from timm==0.9.10) (0.15.2)\n",
      "Requirement already satisfied: pyyaml in /u/yashjain/anaconda3/envs/k4-team1-env/lib/python3.10/site-packages (from timm==0.9.10) (6.0.1)\n",
      "Requirement already satisfied: huggingface-hub in /u/yashjain/anaconda3/envs/k4-team1-env/lib/python3.10/site-packages (from timm==0.9.10) (0.21.4)\n",
      "Requirement already satisfied: safetensors in /u/yashjain/anaconda3/envs/k4-team1-env/lib/python3.10/site-packages (from timm==0.9.10) (0.4.2)\n",
      "Requirement already satisfied: filelock in /u/yashjain/anaconda3/envs/k4-team1-env/lib/python3.10/site-packages (from torch>=1.7->timm==0.9.10) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /u/yashjain/anaconda3/envs/k4-team1-env/lib/python3.10/site-packages (from torch>=1.7->timm==0.9.10) (4.10.0)\n",
      "Requirement already satisfied: sympy in /u/yashjain/anaconda3/envs/k4-team1-env/lib/python3.10/site-packages (from torch>=1.7->timm==0.9.10) (1.12)\n",
      "Requirement already satisfied: networkx in /u/yashjain/anaconda3/envs/k4-team1-env/lib/python3.10/site-packages (from torch>=1.7->timm==0.9.10) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /u/yashjain/anaconda3/envs/k4-team1-env/lib/python3.10/site-packages (from torch>=1.7->timm==0.9.10) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /u/yashjain/anaconda3/envs/k4-team1-env/lib/python3.10/site-packages (from torch>=1.7->timm==0.9.10) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /u/yashjain/anaconda3/envs/k4-team1-env/lib/python3.10/site-packages (from torch>=1.7->timm==0.9.10) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /u/yashjain/anaconda3/envs/k4-team1-env/lib/python3.10/site-packages (from torch>=1.7->timm==0.9.10) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /u/yashjain/anaconda3/envs/k4-team1-env/lib/python3.10/site-packages (from torch>=1.7->timm==0.9.10) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /u/yashjain/anaconda3/envs/k4-team1-env/lib/python3.10/site-packages (from torch>=1.7->timm==0.9.10) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /u/yashjain/anaconda3/envs/k4-team1-env/lib/python3.10/site-packages (from torch>=1.7->timm==0.9.10) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /u/yashjain/anaconda3/envs/k4-team1-env/lib/python3.10/site-packages (from torch>=1.7->timm==0.9.10) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /u/yashjain/anaconda3/envs/k4-team1-env/lib/python3.10/site-packages (from torch>=1.7->timm==0.9.10) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /u/yashjain/anaconda3/envs/k4-team1-env/lib/python3.10/site-packages (from torch>=1.7->timm==0.9.10) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /u/yashjain/anaconda3/envs/k4-team1-env/lib/python3.10/site-packages (from torch>=1.7->timm==0.9.10) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /u/yashjain/anaconda3/envs/k4-team1-env/lib/python3.10/site-packages (from torch>=1.7->timm==0.9.10) (11.7.91)\n",
      "Collecting triton==2.0.0 (from torch>=1.7->timm==0.9.10)\n",
      "  Using cached triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n",
      "Requirement already satisfied: setuptools in /u/yashjain/anaconda3/envs/k4-team1-env/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.7->timm==0.9.10) (68.2.2)\n",
      "Requirement already satisfied: wheel in /u/yashjain/anaconda3/envs/k4-team1-env/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.7->timm==0.9.10) (0.41.2)\n",
      "Requirement already satisfied: cmake in /u/yashjain/anaconda3/envs/k4-team1-env/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.7->timm==0.9.10) (3.28.3)\n",
      "Requirement already satisfied: lit in /u/yashjain/anaconda3/envs/k4-team1-env/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.7->timm==0.9.10) (18.1.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /u/yashjain/anaconda3/envs/k4-team1-env/lib/python3.10/site-packages (from huggingface-hub->timm==0.9.10) (2024.3.1)\n",
      "Requirement already satisfied: requests in /u/yashjain/anaconda3/envs/k4-team1-env/lib/python3.10/site-packages (from huggingface-hub->timm==0.9.10) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /u/yashjain/anaconda3/envs/k4-team1-env/lib/python3.10/site-packages (from huggingface-hub->timm==0.9.10) (4.66.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /u/yashjain/anaconda3/envs/k4-team1-env/lib/python3.10/site-packages (from huggingface-hub->timm==0.9.10) (24.0)\n",
      "Requirement already satisfied: numpy in /u/yashjain/anaconda3/envs/k4-team1-env/lib/python3.10/site-packages (from torchvision->timm==0.9.10) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /u/yashjain/anaconda3/envs/k4-team1-env/lib/python3.10/site-packages (from torchvision->timm==0.9.10) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /u/yashjain/anaconda3/envs/k4-team1-env/lib/python3.10/site-packages (from jinja2->torch>=1.7->timm==0.9.10) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /u/yashjain/anaconda3/envs/k4-team1-env/lib/python3.10/site-packages (from requests->huggingface-hub->timm==0.9.10) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /u/yashjain/anaconda3/envs/k4-team1-env/lib/python3.10/site-packages (from requests->huggingface-hub->timm==0.9.10) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /u/yashjain/anaconda3/envs/k4-team1-env/lib/python3.10/site-packages (from requests->huggingface-hub->timm==0.9.10) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /u/yashjain/anaconda3/envs/k4-team1-env/lib/python3.10/site-packages (from requests->huggingface-hub->timm==0.9.10) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /u/yashjain/anaconda3/envs/k4-team1-env/lib/python3.10/site-packages (from sympy->torch>=1.7->timm==0.9.10) (1.3.0)\n",
      "Using cached triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
      "Installing collected packages: triton\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.2.0\n",
      "    Uninstalling triton-2.2.0:\n",
      "      Successfully uninstalled triton-2.2.0\n",
      "Successfully installed triton-2.0.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install -q ./pip-download-for-segmentation-models-pytorch/pytorch-image-models-0-9-10/timm-0.9.10-py3-none-any.whl \n",
    "!pip install timm==0.9.10\n",
    "# pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "627556be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: munch in /u/yashjain/anaconda3/envs/k4-team1-env/lib/python3.10/site-packages (4.0.0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# !pip install -q ./pip-download-for-segmentation-models-pytorch/munch-4.0.0-py2.py3-none-any.whl\n",
    "!pip install munch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37332020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download from https://www.kaggle.com/code/kashiwaba/pip-download-for-segmentation-models-pytorch/output \n",
    "!pip install -q ./pip-download-for-segmentation-models-pytorch/pretrainedmodels-0.7.4.tar.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c961d25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download from https://www.kaggle.com/code/kashiwaba/pip-download-for-segmentation-models-pytorch/output \n",
    "!pip install -q ./pip-download-for-segmentation-models-pytorch/efficientnet_pytorch-0.7.1.tar.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7a2fa797",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2024-02-12T16:15:54.169884Z",
     "iopub.status.busy": "2024-02-12T16:15:54.169563Z",
     "iopub.status.idle": "2024-02-12T16:15:54.179612Z",
     "shell.execute_reply": "2024-02-12T16:15:54.178599Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.018027,
     "end_time": "2024-02-12T16:15:54.181516",
     "exception": false,
     "start_time": "2024-02-12T16:15:54.163489",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: unrecognized arguments: # change path to point to where you have your conda installation.\n"
     ]
    }
   ],
   "source": [
    "# change path to point to where you have your conda installation.\n",
    "%%writefile /u/yashjain/anaconda3/lib/python3.10/site-packages/triton/common/build.py \n",
    "# https://github.com/openai/triton/issues/2507\n",
    "\n",
    "\n",
    "import contextlib\n",
    "import functools\n",
    "import io\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import sys\n",
    "import sysconfig\n",
    "\n",
    "import setuptools\n",
    "\n",
    "\n",
    "# TODO: is_hip shouldn't be here\n",
    "def is_hip():\n",
    "    import torch\n",
    "    return torch.version.hip is not None\n",
    "\n",
    "\n",
    "@functools.lru_cache()\n",
    "def libcuda_dirs():\n",
    "    libs = subprocess.check_output([\"ldconfig\", \"-p\"]).decode()\n",
    "    # each line looks like the following:\n",
    "    # libcuda.so.1 (libc6,x86-64) => /lib/x86_64-linux-gnu/libcuda.so.1\n",
    "    locs = [line.split()[-1] for line in libs.splitlines() if \"libcuda.so\" in line]\n",
    "    dirs = [os.path.dirname(loc) for loc in locs]\n",
    "    env_ld_library_path = os.getenv(\"LD_LIBRARY_PATH\")\n",
    "    if env_ld_library_path and not dirs:\n",
    "        dirs = [dir for dir in env_ld_library_path.split(\":\") if os.path.exists(os.path.join(dir, \"libcuda.so\"))]\n",
    "    msg = 'libcuda.so cannot found!\\n'\n",
    "    if locs:\n",
    "        msg += 'Possible files are located at %s.' % str(locs)\n",
    "        msg += 'Please create a symlink of libcuda.so to any of the file.'\n",
    "    assert any(os.path.exists(os.path.join(path, 'libcuda.so')) for path in dirs), msg\n",
    "    return dirs\n",
    "\n",
    "\n",
    "@functools.lru_cache()\n",
    "def rocm_path_dir():\n",
    "    return os.getenv(\"ROCM_PATH\", default=\"/opt/rocm\")\n",
    "\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def quiet():\n",
    "    old_stdout, old_stderr = sys.stdout, sys.stderr\n",
    "    sys.stdout, sys.stderr = io.StringIO(), io.StringIO()\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        sys.stdout, sys.stderr = old_stdout, old_stderr\n",
    "\n",
    "\n",
    "@functools.lru_cache()\n",
    "def cuda_include_dir():\n",
    "    base_dir = os.path.join(os.path.dirname(__file__), os.path.pardir)\n",
    "    cuda_path = os.path.join(base_dir, \"third_party\", \"cuda\")\n",
    "    return os.path.join(cuda_path, \"include\")\n",
    "\n",
    "\n",
    "def _build(name, src, srcdir):\n",
    "    if is_hip():\n",
    "        hip_lib_dir = os.path.join(rocm_path_dir(), \"lib\")\n",
    "        hip_include_dir = os.path.join(rocm_path_dir(), \"include\")\n",
    "    else:\n",
    "        cuda_lib_dirs = libcuda_dirs()\n",
    "        cu_include_dir = cuda_include_dir()\n",
    "    suffix = sysconfig.get_config_var('EXT_SUFFIX')\n",
    "    so = os.path.join(srcdir, '{name}{suffix}'.format(name=name, suffix=suffix))\n",
    "    # try to avoid setuptools if possible\n",
    "    cc = os.environ.get(\"CC\")\n",
    "    if cc is None:\n",
    "        # TODO: support more things here.\n",
    "        clang = shutil.which(\"clang\")\n",
    "        gcc = shutil.which(\"gcc\")\n",
    "        cc = gcc if gcc is not None else clang\n",
    "        if cc is None:\n",
    "            raise RuntimeError(\"Failed to find C compiler. Please specify via CC environment variable.\")\n",
    "    # This function was renamed and made public in Python 3.10\n",
    "    if hasattr(sysconfig, 'get_default_scheme'):\n",
    "        scheme = sysconfig.get_default_scheme()\n",
    "    else:\n",
    "        scheme = sysconfig._get_default_scheme()\n",
    "    # 'posix_local' is a custom scheme on Debian. However, starting Python 3.10, the default install\n",
    "    # path changes to include 'local'. This change is required to use triton with system-wide python.\n",
    "    if scheme == 'posix_local':\n",
    "        scheme = 'posix_prefix'\n",
    "    py_include_dir = sysconfig.get_paths(scheme=scheme)[\"include\"]\n",
    "\n",
    "    if is_hip():\n",
    "        ret = subprocess.check_call([cc, src, f\"-I{hip_include_dir}\", f\"-I{py_include_dir}\", f\"-I{srcdir}\", \"-shared\", \"-fPIC\", f\"-L{hip_lib_dir}\", \"-lamdhip64\", \"-o\", so])\n",
    "    else:\n",
    "        cc_cmd = [cc, src, \"-O3\", f\"-I{cu_include_dir}\", f\"-I{py_include_dir}\", f\"-I{srcdir}\", \"-shared\", \"-fPIC\", \"-lcuda\", \"-o\", so]\n",
    "        cc_cmd += [f\"-L{dir}\" for dir in cuda_lib_dirs]\n",
    "        ret = subprocess.check_call(cc_cmd)\n",
    "\n",
    "    if ret == 0:\n",
    "        return so\n",
    "    # fallback on setuptools\n",
    "    extra_compile_args = []\n",
    "    library_dirs = cuda_lib_dirs\n",
    "    include_dirs = [srcdir, cu_include_dir]\n",
    "    libraries = ['cuda']\n",
    "    # extra arguments\n",
    "    extra_link_args = []\n",
    "    # create extension module\n",
    "    ext = setuptools.Extension(\n",
    "        name=name,\n",
    "        language='c',\n",
    "        sources=[src],\n",
    "        include_dirs=include_dirs,\n",
    "        extra_compile_args=extra_compile_args + ['-O3'],\n",
    "        extra_link_args=extra_link_args,\n",
    "        library_dirs=library_dirs,\n",
    "        libraries=libraries,\n",
    "    )\n",
    "    # build extension module\n",
    "    args = ['build_ext']\n",
    "    args.append('--build-temp=' + srcdir)\n",
    "    args.append('--build-lib=' + srcdir)\n",
    "    args.append('-q')\n",
    "    args = dict(\n",
    "        name=name,\n",
    "        ext_modules=[ext],\n",
    "        script_args=args,\n",
    "    )\n",
    "    with quiet():\n",
    "        setuptools.setup(**args)\n",
    "    return so"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988e9787",
   "metadata": {
    "papermill": {
     "duration": 0.004887,
     "end_time": "2024-02-12T16:15:54.191148",
     "exception": false,
     "start_time": "2024-02-12T16:15:54.186261",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0e7576",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-12T16:15:54.201754Z",
     "iopub.status.busy": "2024-02-12T16:15:54.201474Z",
     "iopub.status.idle": "2024-02-12T16:15:54.206820Z",
     "shell.execute_reply": "2024-02-12T16:15:54.205959Z"
    },
    "papermill": {
     "duration": 0.012936,
     "end_time": "2024-02-12T16:15:54.208790",
     "exception": false,
     "start_time": "2024-02-12T16:15:54.195854",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting inference.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile inference.sh\n",
    "#!/bin/bash \n",
    "\n",
    "SEED=42\n",
    "BACKBONE=convnext_tiny\n",
    "CKPT_PATH=\"/u/yashjain/kaggle_4/winning-team-solutions/team-1/model_weights/convnext_tiny_1536_customloss_e20.pth|/u/yashjain/kaggle_4/winning-team-solutions/team-1/model_weights/convnext_tiny_1536_customloss_3drot_e30.pth\"\n",
    "IN_CHANNELS=3\n",
    "NUM_CLASSES=3\n",
    "IMAGE_SIZE=3072\n",
    "BATCH_SIZE=2\n",
    "THRESHOLD=0.4\n",
    "AXIS=\"z|y|x\"\n",
    "FLIP=5\n",
    "ROT=3\n",
    "\n",
    "for group in kidney_6 kidney_5; do\n",
    "    python inference.py \\\n",
    "    --seed $SEED \\\n",
    "    --group $group \\\n",
    "    --backbone $BACKBONE \\\n",
    "    --ckpt_path $CKPT_PATH \\\n",
    "    --in_channels $IN_CHANNELS \\\n",
    "    --num_classes $NUM_CLASSES \\\n",
    "    --image_size $IMAGE_SIZE \\\n",
    "    --batch_size $BATCH_SIZE \\\n",
    "    --axis $AXIS \\\n",
    "    --flip $FLIP \\\n",
    "    --rot $ROT \\\n",
    "    --overlap \\\n",
    "    --threshold $THRESHOLD\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33b188c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-12T16:15:54.220056Z",
     "iopub.status.busy": "2024-02-12T16:15:54.219794Z",
     "iopub.status.idle": "2024-02-12T16:15:54.233467Z",
     "shell.execute_reply": "2024-02-12T16:15:54.232574Z"
    },
    "papermill": {
     "duration": 0.021836,
     "end_time": "2024-02-12T16:15:54.235544",
     "exception": false,
     "start_time": "2024-02-12T16:15:54.213708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile inference.py\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import cc3d\n",
    "import timm\n",
    "import shutil\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import albumentations as A\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Download from https://www.kaggle.com/datasets/clevert/segmentation-models-pytorch-extra-stem-2-5d \n",
    "sys.path.append(\"/u/yashjain/kaggle_4/winning-team-solutions/team-1/segmentation-models-pytorch-extra-stem-2-5d\")\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "############################################### helper functions ##################################################\n",
    "def rle_encode(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels = img.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    rle = ' '.join(str(x) for x in runs)\n",
    "    if rle=='':\n",
    "        rle = '1 0'\n",
    "    return rle\n",
    "\n",
    "def is_dist_avail_and_initialized():\n",
    "    if not dist.is_available():\n",
    "        return False\n",
    "    if not dist.is_initialized():\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def get_world_size():\n",
    "    if not is_dist_avail_and_initialized():\n",
    "        return 1\n",
    "    return dist.get_world_size()\n",
    "\n",
    "\n",
    "def get_rank():\n",
    "    if not is_dist_avail_and_initialized():\n",
    "        return 0\n",
    "    return dist.get_rank()\n",
    "\n",
    "\n",
    "def is_main_process():\n",
    "    return get_rank() == 0\n",
    "\n",
    "\n",
    "def build_model(backbone, in_channels, num_classes):\n",
    "    model = smp.Unet(\n",
    "        encoder_name=backbone,\n",
    "        encoder_weights=None,\n",
    "        encoder_args={\"in_channels\": in_channels},\n",
    "        decoder_norm_type=\"GN\",\n",
    "        decoder_act_type=\"GeLU\",\n",
    "        decoder_upsample_method=\"nearest\",\n",
    "        in_channels=in_channels,\n",
    "        classes=num_classes,\n",
    "        activation=None,\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def filter_checkpoint(state_dict):\n",
    "    new_state_dict = {}\n",
    "    for k, v in state_dict.items():\n",
    "        new_state_dict[k.replace(\"module.\", \"\")] = v\n",
    "    return new_state_dict\n",
    "\n",
    "\n",
    "def load_model(backbone, in_channels, num_classes, path):\n",
    "    model = build_model(backbone, in_channels, num_classes)\n",
    "    state_dict = torch.load(path, map_location=\"cpu\")\n",
    "    state_dict = filter_checkpoint(state_dict)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "class Ensemble(object):\n",
    "    def __init__(self, backbone, in_channels, num_classes, ckpts, device):\n",
    "        self.models = []\n",
    "        for ckpt_path in ckpts:\n",
    "            model = load_model(backbone, in_channels, num_classes, ckpt_path).to(device)\n",
    "            model = torch.compile(model)\n",
    "            self.models.append(model)\n",
    "            \n",
    "    def __call__(self, x):\n",
    "        out = None\n",
    "        for model in self.models:\n",
    "            if out is None:\n",
    "                out = model(x).sigmoid()\n",
    "            else:\n",
    "                out += model(x).sigmoid()\n",
    "        out /= len(self.models)\n",
    "        return out\n",
    "\n",
    "\n",
    "class InferenceDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    axis2dim = {\"z\": 0, \"y\": 1, \"x\": 2}\n",
    "    \n",
    "    def __init__(self, volume_path, volume_shape, local_rank, world_size, in_channels=3, image_size=512, axis=\"z\"):\n",
    "        self.volume_path = volume_path\n",
    "        self.volume_shape = volume_shape\n",
    "        self.axis = axis\n",
    "        self.in_channels = in_channels\n",
    "        self.image_size = image_size\n",
    "        block = self.volume_shape[self.axis2dim[self.axis]] // world_size\n",
    "        if local_rank < world_size-1:\n",
    "            self.indexs = range(self.volume_shape[self.axis2dim[self.axis]])[local_rank*block:(local_rank+1)*block]\n",
    "        else:\n",
    "            self.indexs = range(self.volume_shape[self.axis2dim[self.axis]])[local_rank*block:]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.indexs)\n",
    "    \n",
    "    def load_image(self, idx):\n",
    "        idx = self.indexs[idx]\n",
    "        volume = np.memmap(self.volume_path, shape=self.volume_shape, dtype=np.uint16, mode=\"r\")\n",
    "        idxs = np.clip(range(idx-self.in_channels//2, idx+self.in_channels//2+1), 0, self.volume_shape[self.axis2dim[self.axis]]-1)\n",
    "        if self.axis == \"z\":\n",
    "            image =  volume[idxs].transpose(1, 2, 0)\n",
    "        elif self.axis == \"x\":\n",
    "            image =  volume[:, :, idxs]\n",
    "        else:\n",
    "            image =  volume[:, idxs, :].transpose(0, 2, 1)\n",
    "        image = image.astype(np.float32)\n",
    "        image = image / 65535.0\n",
    "        return image\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.load_image(idx)\n",
    "        orig_size = image.shape\n",
    "        area = self.image_size**2\n",
    "        orig_area = orig_size[0]*orig_size[1]\n",
    "        scale = np.sqrt(area/orig_area)\n",
    "        new_h = int(orig_size[0]*scale) if int(orig_size[0]*scale) % 32 == 0 else int(orig_size[0]*scale) - (int(orig_size[0]*scale)%32) + 32\n",
    "        new_w = int(orig_size[1]*scale) if int(orig_size[1]*scale) % 32 == 0 else int(orig_size[1]*scale) - (int(orig_size[1]*scale)%32) + 32\n",
    "        # LANCZOS4 is slighter better than bilinear and bicubic\n",
    "        image = cv2.resize(image, (new_w, new_h), cv2.INTER_LANCZOS4)\n",
    "        image = torch.tensor(np.transpose(image, (2, 0, 1)))\n",
    "        return self.indexs[idx], image, torch.tensor(np.array([orig_size[0], orig_size[1]]))\n",
    "    \n",
    "\n",
    "############################################### main ##################################################\n",
    "\n",
    "def main_worker(rank, args, queue):\n",
    "    \n",
    "    torch.backends.cudnn_benchmark = True\n",
    "    \n",
    "    # set device\n",
    "    device = torch.device(f\"cuda:{rank}\")\n",
    "    \n",
    "    # meta info\n",
    "    volume_shape = args.volume_shape\n",
    "    volume_path = args.volume_path\n",
    "        \n",
    "    # build model\n",
    "    model = Ensemble(args.backbone, args.in_channels, args.num_classes, args.ckpt_path, device)\n",
    "    \n",
    "    # inference \n",
    "    with torch.no_grad():\n",
    "        for size in args.image_size:\n",
    "            for axis in args.axis:\n",
    "                test_dataset = InferenceDataset(volume_path, volume_shape, rank, args.num_processes, args.in_channels, image_size=size, axis=axis)\n",
    "                test_loader = DataLoader(test_dataset, batch_size=args.batch_size, num_workers=4, pin_memory=True)\n",
    "                max_len = test_dataset.volume_shape[test_dataset.axis2dim[axis]]\n",
    "                pbar = tqdm(enumerate(test_loader), total=len(test_loader), desc=f'Inference {args.group} {axis}', ncols=150)\n",
    "                for step, (idx, images, shapes) in pbar:\n",
    "                    shape = shapes[0].numpy()\n",
    "                    idx = idx.numpy()\n",
    "                    images = images.to(device, non_blocking=True)\n",
    "                    bsz = images.size(0)\n",
    "                    batch_pred_mask = torch.zeros(bsz, args.num_classes, shape[0], shape[1]).to(device)\n",
    "                    for aug, flip in zip([torch.flip]*len(args.flip)+[partial(torch.rot90, dims=[2, 3])]*len(args.rot), args.flip+args.rot):\n",
    "                        with torch.cuda.amp.autocast(enabled=True):\n",
    "                            preds = model(aug(images, flip))\n",
    "                            flip = -flip if not isinstance(flip, list) else flip\n",
    "                            preds = F.interpolate(aug(preds, flip).float(), (int(shape[0]), int(shape[1])), mode='bicubic')\n",
    "                        batch_pred_mask += preds\n",
    "                    \n",
    "                    batch_pred_mask /= len(args.axis) * (len(args.flip)+len(args.rot)) * len(args.image_size)\n",
    "                    if args.overlap:\n",
    "                        batch_pred_mask /= args.num_classes\n",
    "                    masks = batch_pred_mask.to(torch.float16).cpu().numpy()\n",
    "                    queue.put((axis, idx, masks, max_len))\n",
    "                    pbar.set_postfix(shape=images.shape)\n",
    "                        \n",
    "                        \n",
    "def write_worker(args, queue, write_lock):\n",
    "    while True:\n",
    "        axis, idx, masks, max_len = queue.get()\n",
    "        if idx is None:\n",
    "            break\n",
    "        with write_lock:\n",
    "            pred_masks = np.memmap(args.mask_path, shape=args.volume_shape, dtype=np.float16, mode=\"r+\")\n",
    "            if args.overlap:\n",
    "                for i in range(args.num_classes):\n",
    "                    mask = masks[:, i, ...]\n",
    "                    offset = i - args.num_classes // 2\n",
    "                    idxs = np.clip(idx+offset, 0, max_len-1)\n",
    "                    if axis == \"z\":\n",
    "                        pred_masks[idxs, :, :] += mask\n",
    "                    elif axis == \"y\":\n",
    "                        pred_masks[:, idxs, :] += mask.transpose(1, 0, 2)\n",
    "                    else:\n",
    "                        pred_masks[:, :, idxs] += mask.transpose(1, 2, 0)\n",
    "            else:\n",
    "                mask = masks[:, args.num_classes//2, ...]\n",
    "                idxs = np.clip(idx, 0, max_len-1)\n",
    "                if axis == \"z\":\n",
    "                    pred_masks[idxs, :, :] += mask\n",
    "                elif axis == \"y\":\n",
    "                    pred_masks[:, idxs, :] += mask.transpose(1, 0, 2)\n",
    "                else:\n",
    "                    pred_masks[:, :, idxs] += mask.transpose(1, 2, 0)\n",
    "            pred_masks.flush()\n",
    "            del pred_masks, masks, axis, idx, max_len\n",
    "                        \n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    parser.add_argument(\"--seed\", type=int, default=42)\n",
    "    parser.add_argument(\"--group\", type=str, default=\"kidney_5\")\n",
    "    parser.add_argument(\"--backbone\", type=str, default=\"convnext_tiny\")\n",
    "    parser.add_argument(\"--in_channels\", type=int, default=3)\n",
    "    parser.add_argument(\"--num_classes\", type=int, default=3)\n",
    "    parser.add_argument(\"--ckpt_path\", type=str, default=\"\")\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=3)\n",
    "    parser.add_argument(\"--image_size\", type=int, default=2560)\n",
    "    parser.add_argument(\"--axis\", type=str, default=\"z|y|x\")\n",
    "    parser.add_argument(\"--flip\", type=int, default=3)\n",
    "    parser.add_argument(\"--rot\", type=int, default=3)\n",
    "    parser.add_argument(\"--overlap\", action=\"store_true\", default=False)\n",
    "    parser.add_argument(\"--threshold\", type=float, default=0.5)\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    args.image_size = [args.image_size]\n",
    "    args.axis = args.axis.split(\"|\")\n",
    "    args.flip = [[], [1], [2], [3], [2,3]][:args.flip]\n",
    "    args.rot = [1, 2, 3][:args.rot]\n",
    "    args.ckpt_path = args.ckpt_path.split(\"|\")\n",
    "    args.num_processes = torch.cuda.device_count()\n",
    "    \n",
    "    ls_images = sorted(glob(os.path.join(\"/u/yashjain/kaggle_4/competition-data/full-test-dataset\", args.group, \"images\", \"*.tif\")))\n",
    "    h, w = cv2.imread(ls_images[-1], cv2.IMREAD_UNCHANGED).shape\n",
    "    volume_shape = (len(ls_images), h, w)\n",
    "    volume_path = f\"/dev/shm/{args.group}.mmap\"\n",
    "    mask_path = f\"/dev/shm/{args.group}_mask.mmap\"\n",
    "    if not os.path.exists(volume_path):\n",
    "        volume = np.memmap(volume_path, shape=volume_shape, dtype=np.uint16, mode=\"w+\")\n",
    "        for i, path in enumerate(tqdm(ls_images, total=len(ls_images), desc=f\"Caching {args.group} images\")):\n",
    "            image = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "            volume[i] = image\n",
    "        volume.flush()\n",
    "        del volume\n",
    "    if not os.path.exists(mask_path):\n",
    "        mask = np.memmap(mask_path, shape=volume_shape, dtype=np.float16, mode=\"w+\")\n",
    "        mask.fill(0.0)\n",
    "        mask.flush()\n",
    "        del mask\n",
    "    \n",
    "    args.volume_shape = volume_shape\n",
    "    args.volume_path = volume_path\n",
    "    args.mask_path = mask_path\n",
    "    \n",
    "    # inference\n",
    "    queue = mp.Queue()\n",
    "    write_lock = mp.Lock()\n",
    "    inference_processes = []\n",
    "    write_processes = []\n",
    "    for rank in range(args.num_processes):\n",
    "        p = mp.Process(target=main_worker, args=(rank, args, queue))\n",
    "        p.start()\n",
    "        inference_processes.append(p)\n",
    "    for rank in range(args.num_processes*2):\n",
    "        p = mp.Process(target=write_worker, args=(args, queue, write_lock))\n",
    "        p.start()\n",
    "        write_processes.append(p)\n",
    "    for p in inference_processes:\n",
    "        p.join()\n",
    "    for _ in range(args.num_processes*2):\n",
    "        queue.put((None, None, None, None))\n",
    "    for p in write_processes:\n",
    "        p.join()\n",
    "        \n",
    "    # write to csv\n",
    "    rles, ids = [], []\n",
    "    pred_masks = np.memmap(args.mask_path, shape=args.volume_shape, dtype=np.float16, mode=\"r\")\n",
    "    for i in tqdm(range(len(ls_images)), total=len(ls_images)):\n",
    "        pred_mask = pred_masks[i, :, :]\n",
    "        pred_mask = (pred_mask > args.threshold).astype(np.uint8)\n",
    "        rle = rle_encode(pred_mask)\n",
    "        path = ls_images[i].split(os.path.sep)\n",
    "        dataset = path[-3]\n",
    "        slice_id, _ = os.path.splitext(path[-1])\n",
    "        rles.append(rle)\n",
    "        ids.append(f\"{dataset}_{slice_id}\")\n",
    "        \n",
    "    df = pd.DataFrame.from_dict({\n",
    "        \"id\": ids,\n",
    "        \"rle\": rles\n",
    "    })\n",
    "    df.to_csv(f\"{args.group}.csv\", index=False)\n",
    "    del pred_masks\n",
    "    \n",
    "    # clean up memmap files\n",
    "    os.remove(args.volume_path)\n",
    "    os.remove(args.mask_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7a2bdf",
   "metadata": {
    "papermill": {
     "duration": 0.004855,
     "end_time": "2024-02-12T16:15:54.245578",
     "exception": false,
     "start_time": "2024-02-12T16:15:54.240723",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c442c8a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-12T16:15:54.256882Z",
     "iopub.status.busy": "2024-02-12T16:15:54.256584Z",
     "iopub.status.idle": "2024-02-12T16:15:55.120222Z",
     "shell.execute_reply": "2024-02-12T16:15:55.119401Z"
    },
    "papermill": {
     "duration": 0.872429,
     "end_time": "2024-02-12T16:15:55.122950",
     "exception": false,
     "start_time": "2024-02-12T16:15:54.250521",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1733592/3665373954.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/u/yashjain/kaggle_4/winning-team-solutions/team-1/inference.py:10: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "Caching kidney_6 images: 100%|█████████████| 1909/1909 [00:08<00:00, 232.12it/s]\n",
      "Inference kidney_6 z: 100%|███████████████████████████████████████████████████| 477/477 [18:01<00:00,  2.27s/it, shape=torch.Size([2, 3, 2784, 3424])]\n",
      "Inference kidney_6 z: 100%|███████████████████████████████████████████████████| 478/478 [18:31<00:00,  2.33s/it, shape=torch.Size([1, 3, 2784, 3424])]\n",
      "Inference kidney_6 y: 100%|███████████████████████████████████████████████████| 257/257 [09:52<00:00,  2.30s/it, shape=torch.Size([2, 3, 3808, 2496])]\n",
      "Inference kidney_6 y: 100%|███████████████████████████████████████████████████| 257/257 [09:52<00:00,  2.30s/it, shape=torch.Size([2, 3, 3808, 2496])]\n",
      "Inference kidney_6 x: 100%|███████████████████████████████████████████████████| 314/314 [11:52<00:00,  2.27s/it, shape=torch.Size([2, 3, 4192, 2272])]\n",
      "Inference kidney_6 x: 100%|███████████████████████████████████████████████████| 315/315 [12:20<00:00,  2.35s/it, shape=torch.Size([1, 3, 4192, 2272])]\n",
      "100%|██████████████████████████████████████| 1909/1909 [00:09<00:00, 196.99it/s]\n",
      "/u/yashjain/kaggle_4/winning-team-solutions/team-1/inference.py:10: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "Caching kidney_5 images: 100%|█████████████| 2363/2363 [00:14<00:00, 168.33it/s]\n",
      "Inference kidney_5 z: 100%|███████████████████████████████████████████████████| 591/591 [21:55<00:00,  2.23s/it, shape=torch.Size([2, 3, 2816, 3392])]\n",
      "Inference kidney_5 z: 100%|███████████████████████████████████████████████████| 591/591 [22:20<00:00,  2.27s/it, shape=torch.Size([1, 3, 2816, 3392])]\n",
      "Inference kidney_5 y: 100%|███████████████████████████████████████████████████| 333/333 [13:12<00:00,  2.38s/it, shape=torch.Size([1, 3, 3744, 2528])]\n",
      "Inference kidney_5 y: 100%|███████████████████████████████████████████████████| 333/333 [13:11<00:00,  2.38s/it, shape=torch.Size([1, 3, 3744, 2528])]\n",
      "Inference kidney_5 x: 100%|███████████████████████████████████████████████████| 400/400 [15:16<00:00,  2.29s/it, shape=torch.Size([1, 3, 4096, 2304])]\n",
      "Inference kidney_5 x: 100%|███████████████████████████████████████████████████| 400/400 [15:13<00:00,  2.28s/it, shape=torch.Size([1, 3, 4096, 2304])]\n",
      "100%|██████████████████████████████████████| 2363/2363 [00:21<00:00, 109.87it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "\n",
    "debug = False\n",
    "\n",
    "# if len(glob(\"/teradata/hra_data/k4_data/competition-data/test/kidney_5/images/*.tif\")) == 3 and not debug:\n",
    "if len(glob(\"/u/yashjain/kaggle_4/competition-data/full-test-dataset/kidney_5/images/*.tif\")) == 3 and not debug:\n",
    "    ids = [f\"kidney_5_{i:04d}\" for i in range(3)] + [f\"kidney_6_{i:04d}\" for i in range(3)]\n",
    "    rles = [\"1 0\"] * 6\n",
    "    submission = pd.DataFrame.from_dict({\n",
    "        \"id\": ids,\n",
    "        \"rle\": rles\n",
    "    })\n",
    "else:\n",
    "    !bash inference.sh\n",
    "    kidney_5 = pd.read_csv(\"kidney_5.csv\")\n",
    "    kidney_6 = pd.read_csv(\"kidney_6.csv\")\n",
    "    submission = pd.concat([kidney_5, kidney_6]).reset_index(drop=True)\n",
    "    \n",
    "# submission.to_csv(\"submission-val.csv\", index=False)\n",
    "\n",
    "submission.to_csv(\"team-1-full-test-set-predictions-ensemble-model.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea8ca9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-12T16:15:55.136453Z",
     "iopub.status.busy": "2024-02-12T16:15:55.136085Z",
     "iopub.status.idle": "2024-02-12T16:15:55.153760Z",
     "shell.execute_reply": "2024-02-12T16:15:55.152833Z"
    },
    "papermill": {
     "duration": 0.026777,
     "end_time": "2024-02-12T16:15:55.155992",
     "exception": false,
     "start_time": "2024-02-12T16:15:55.129215",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kidney_5_0000</td>\n",
       "      <td>1 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kidney_5_0001</td>\n",
       "      <td>1 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kidney_5_0002</td>\n",
       "      <td>1 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kidney_5_0003</td>\n",
       "      <td>1 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kidney_5_0004</td>\n",
       "      <td>1 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1508</th>\n",
       "      <td>kidney_6_0586</td>\n",
       "      <td>279734 2 280991 2 282248 2 292248 2 293505 2 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1509</th>\n",
       "      <td>kidney_6_0587</td>\n",
       "      <td>277220 1 278477 2 279734 2 280992 1 292249 1 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1510</th>\n",
       "      <td>kidney_6_0588</td>\n",
       "      <td>269672 2 270931 1 274705 2 275963 1 277220 1 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511</th>\n",
       "      <td>kidney_6_0589</td>\n",
       "      <td>268414 1 270931 2 272189 2 273447 2 287224 1 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512</th>\n",
       "      <td>kidney_6_0590</td>\n",
       "      <td>303562 1 304819 1 306076 2 307333 2 308590 2 3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1513 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                                rle\n",
       "0     kidney_5_0000                                                1 0\n",
       "1     kidney_5_0001                                                1 0\n",
       "2     kidney_5_0002                                                1 0\n",
       "3     kidney_5_0003                                                1 0\n",
       "4     kidney_5_0004                                                1 0\n",
       "...             ...                                                ...\n",
       "1508  kidney_6_0586  279734 2 280991 2 282248 2 292248 2 293505 2 2...\n",
       "1509  kidney_6_0587  277220 1 278477 2 279734 2 280992 1 292249 1 2...\n",
       "1510  kidney_6_0588  269672 2 270931 1 274705 2 275963 1 277220 1 2...\n",
       "1511  kidney_6_0589  268414 1 270931 2 272189 2 273447 2 287224 1 2...\n",
       "1512  kidney_6_0590  303562 1 304819 1 306076 2 307333 2 308590 2 3...\n",
       "\n",
       "[1513 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f7a1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os \n",
    "sys.path.append(f'{os.getcwd()}/sennet-metrics')\n",
    "sys.path.append(f'{os.getcwd()}/sennet-metrics/src')\n",
    "\n",
    "from sennet_metrices import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f57743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kidney_5_submit_df shape: (1012, 2)\n",
      "kidney_6_submit_df shape: (501, 2)\n",
      "kidney_5_label_df shape: (1012, 7)\n",
      "kidney_6_label_df shape: (501, 7)\n",
      "Surface dice for public test (kidney_5) set is: 0.8910258412361145\n",
      "Surface dice for private test (kidney_6) set is: 0.7743535041809082\n"
     ]
    }
   ],
   "source": [
    "# Compute competition metric.\n",
    "\n",
    "submit_df = pd.read_csv('submission-val.csv')\n",
    "label_df = pd.read_csv('/teradata/hra_data/k4_data/competition-data/solution.csv')\n",
    "\n",
    "# Check the id column of the dataframe and separate rows into two dataframes based on if the values contains \"kidney_5\" or \"kidney_6\".\n",
    "kidney_5_submit_df = submit_df[submit_df['id'].str.contains('kidney_5')]\n",
    "kidney_6_submit_df = submit_df[submit_df['id'].str.contains('kidney_6')]\n",
    "print(f'kidney_5_submit_df shape: {kidney_5_submit_df.shape}')\n",
    "print(f'kidney_6_submit_df shape: {kidney_6_submit_df.shape}')\n",
    "\n",
    "kidney_5_label_df = label_df[label_df['id'].str.contains('kidney_5')]\n",
    "kidney_6_label_df = label_df[label_df['id'].str.contains('kidney_6')]\n",
    "print(f'kidney_5_label_df shape: {kidney_5_label_df.shape}')\n",
    "print(f'kidney_6_label_df shape: {kidney_6_label_df.shape}')\n",
    "\n",
    "kidney_5_submit_df.reset_index(inplace=True)\n",
    "kidney_6_submit_df.reset_index(inplace=True)\n",
    "kidney_5_label_df.reset_index(inplace=True)\n",
    "kidney_6_label_df.reset_index(inplace=True)\n",
    "\n",
    "## -------------- Surface Dice --------------\n",
    "surface_dice_kidney_5 = compute_surface_dice_score(kidney_5_submit_df, kidney_5_label_df)\n",
    "print(f'Surface dice for public test (kidney_5) set is: {surface_dice_kidney_5}')\n",
    "\n",
    "surface_dice_kidney_6 = compute_surface_dice_score(kidney_6_submit_df, kidney_6_label_df)\n",
    "print(f'Surface dice for private test (kidney_6) set is: {surface_dice_kidney_6}')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 6962461,
     "sourceId": 61446,
     "sourceType": "competition"
    },
    {
     "datasetId": 4016367,
     "sourceId": 6988238,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4009913,
     "sourceId": 7047232,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4055366,
     "sourceId": 7047382,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4071363,
     "sourceId": 7070094,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4072639,
     "sourceId": 7073418,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4055374,
     "sourceId": 7205725,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4181456,
     "sourceId": 7224027,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4206264,
     "sourceId": 7258395,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4237589,
     "sourceId": 7304002,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4242527,
     "sourceId": 7311364,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4245320,
     "sourceId": 7315836,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4245329,
     "sourceId": 7321059,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4266569,
     "sourceId": 7350318,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4271235,
     "sourceId": 7354364,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4271108,
     "sourceId": 7354626,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4272204,
     "sourceId": 7359335,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4279640,
     "sourceId": 7367471,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4284491,
     "sourceId": 7373862,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4284499,
     "sourceId": 7373875,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4284599,
     "sourceId": 7374032,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4288797,
     "sourceId": 7380046,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4289816,
     "sourceId": 7381525,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4296436,
     "sourceId": 7390847,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4322047,
     "sourceId": 7434865,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4342221,
     "sourceId": 7460678,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4364681,
     "sourceId": 7495928,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4433048,
     "sourceId": 7612672,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 150248402,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 150386064,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30580,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 303.431776,
   "end_time": "2024-02-12T16:15:55.480388",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-02-12T16:10:52.048612",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
